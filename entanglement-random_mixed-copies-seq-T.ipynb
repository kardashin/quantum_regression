{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a554c6f8-394e-4c32-af26-877a6f70cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qpe import *\n",
    "\n",
    "from numpy.random import permutation\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "matplotlib.rcParams['font.family']='serif'\n",
    "matplotlib.rcParams['axes.unicode_minus']=False\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "matplotlib.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d4f24c-9791-47ff-892f-1d2b32442b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aux_info(dms, labels, n_layers, pars, n_copies=1, n_meas=0):\n",
    "\n",
    "    n_inp = int(log2(len(dms[0])))\n",
    "    n_tot = n_inp*n_copies\n",
    "    d = 2**n_tot\n",
    "    d_diff = 2**(n_tot - n_meas)\n",
    "    \n",
    "    if n_meas == 0:\n",
    "        n_meas = n_tot\n",
    "    \n",
    "    pars_ans = pars[:-2**n_meas]\n",
    "    pars_est = pars[-2**n_meas:]\n",
    "    \n",
    "    ansatz = hea_cry_rzrx(n_tot, n_layers, pars_ans)\n",
    "\n",
    "    obs_u = ansatz.conj().T@kron_A_N(diag(pars_est), d_diff)@ansatz\n",
    "    obs_u_sq = obs_u@obs_u\n",
    "    \n",
    "    # projs = [reduce(kron, [diag(line), eye(2**(n_tot - n_meas))]) for line in eye(2**n_meas)]\n",
    "    # projs_u = [ansatz.conj().T@proj@ansatz for proj in projs]\n",
    "\n",
    "    dms_cop = [reduce(kron, [dm]*n_copies) for dm in dms]\n",
    "    \n",
    "    expecs = []\n",
    "    disps = []\n",
    "    for dm in dms_cop:\n",
    "        expec = trace(dm@obs_u).real\n",
    "        disp = trace(dm@obs_u_sq).real - expec**2\n",
    "        expecs.append(expec)\n",
    "        disps.append(disp)\n",
    "        \n",
    "    \n",
    "    return array(expecs), array(disps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23c77dd-6d28-45b3-bbf2-d00785ad47bb",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31899640-8439-4f94-bcdc-6af2af67c1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\r"
     ]
    }
   ],
   "source": [
    "n_inp = 2\n",
    "n_test = 10000\n",
    "mixed = True\n",
    "marks = \"neg\"\n",
    "\n",
    "dms_test, labels_test = gen_even_ent_data(n_test, n_inp=n_inp, mixed=mixed, marks=marks, eps=1e-3)\n",
    "purities_test = [trace(dm@dm).real for dm in dms_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bbea4a-e458-4806-8e18-da70de43ce20",
   "metadata": {},
   "source": [
    "# Pass $T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da304dd-8d56-45b3-968f-504458892ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_copies = 4\n",
    "n_layers = 2\n",
    "n_tot = n_inp*n_copies\n",
    "n_meas = n_inp*n_copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d5cbf72-c3c8-4a40-b717-3a0291741387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kardashin/Work/QPE/Results/Entanglement/Training_set_size/c=4-m=8-l=2-w_ls=1.0-w_var=0.0001-T=(100,1000,100)-BFGS'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_ls = 1e0\n",
    "w_var = 1e-4\n",
    "method = \"BFGS\"\n",
    "options = {\"maxiter\": 5000}#, \"maxfun\": int(1e10)}##\n",
    "T_min, T_max, T_step = 100, 1000, 100\n",
    "n_train_list = arange(T_min, T_max + 1, T_step)\n",
    "\n",
    "n_runs = 1\n",
    "\n",
    "path = \"/home/kardashin/Work/QPE/Results/Entanglement/Training_set_size/\"\n",
    "pref = \"c=%d-m=%d-l=%d-w_ls=%.1f-w_var=%.4f-T=(%d,%d,%d)-%s\" %(n_copies, n_meas, n_layers, w_ls, w_var, T_min, T_max, T_step, method)\n",
    "path + pref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c710c974-7b21-46a1-95e6-4db8a745f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dms_train = np.load(path + \"c=4-m=8-l=2-w_ls=1.0-w_var=0.0001-T=(100,1000,100)-BFGS-r=0-dms_train.npy\")\n",
    "# labels_train = np.load(path + \"c=4-m=8-l=2-w_ls=1.0-w_var=0.0001-T=(100,1000,100)-BFGS-r=0-labels_train.npy\")\n",
    "# fvals = np.load(path + \"c=4-m=8-l=2-w_ls=1.0-w_var=0.0001-T=(100,1000,100)-BFGS-r=0-Tr=100-fvals.npy\")\n",
    "# pars = np.load(path + \"c=4-m=8-l=2-w_ls=1.0-w_var=0.0001-T=(100,1000,100)-BFGS-r=0-Tr=100-pars.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cda6ce-6f54-4172-88c5-af387d41eb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: 1\n",
      "\tT: 100\n",
      "\t\tTraining\n",
      "\t\t\tIteration: 3181 | Cost: 0.01296139 | Time passed: 130796 s\n",
      "\t\t\tFinished in 130796.88060045242\n",
      "\t\t\t Optimization terminated successfully.\n",
      "\t\t\tCost: 0.01296139491703775\n",
      "\t\tTesting\n",
      "\t\t\tTesting error: 80.82745245432615\n",
      "\tT: 200\n",
      "\t\tTraining\n",
      "\t\t\tIteration: 2535 | Cost: 0.05405531 | Time passed: 185544 s\n",
      "\t\t\tFinished in 185545.07245969772\n",
      "\t\t\t Optimization terminated successfully.\n",
      "\t\t\tCost: 0.054055309458374494\n",
      "\t\tTesting\n",
      "\t\t\tTesting error: 49.57710753148997\n",
      "\tT: 300\n",
      "\t\tTraining\n",
      "\t\t\tIteration: 1214 | Cost: 0.11975786 | Time passed: 133625 s\n",
      "\t\t\tFinished in 133625.25820827484\n",
      "\t\t\t Optimization terminated successfully.\n",
      "\t\t\tCost: 0.11975785777190334\n",
      "\t\tTesting\n",
      "\t\t\tTesting error: 52.99045262491971\n",
      "\tT: 400\n",
      "\t\tTraining\n",
      "\t\t\tIteration: 1345 | Cost: 0.23863024 | Time passed: 190549 s\n",
      "\t\t\tFinished in 190549.2892127037\n",
      "\t\t\t Optimization terminated successfully.\n",
      "\t\t\tCost: 0.23863023599866992\n",
      "\t\tTesting\n",
      "\t\t\tTesting error: 38.66625676791716\n",
      "\tT: 500\n",
      "\t\tTraining\n",
      "\t\t\tIteration: 1172 | Cost: 0.38120111 | Time passed: 199391 s\n",
      "\t\t\tFinished in 199391.19363713264\n",
      "\t\t\t Optimization terminated successfully.\n",
      "\t\t\tCost: 0.38120110986247524\n",
      "\t\tTesting\n",
      "\t\t\tTesting error: 34.25500630918286\n",
      "\tT: 600\n",
      "\t\tTraining\n",
      "\t\t\tIteration: 1330 | Cost: 0.54435917 | Time passed: 263300 s\n",
      "\t\t\tFinished in 263301.1169667244\n",
      "\t\t\t Optimization terminated successfully.\n",
      "\t\t\tCost: 0.5443591722571564\n",
      "\t\tTesting\n",
      "\t\t\tTesting error: 29.179537302241663\n",
      "\tT: 700\n",
      "\t\tTraining\n",
      "\t\t\tIteration: 75 | Cost: 0.74302646 | Time passed: 18269 s\r"
     ]
    }
   ],
   "source": [
    "fvals_list = []\n",
    "xf_list = []\n",
    "nfev_list = []\n",
    "time_list = []\n",
    "error_test_list = []\n",
    "dms_train_full_list = []\n",
    "labels_train_full_list = []\n",
    "\n",
    "for r in range(n_runs):\n",
    "    print(\"run: %d\" %(r + 1))\n",
    "\n",
    "    dms_train_full, labels_train_full = gen_even_ent_data(n_train_list[-1], n_inp=n_inp, mixed=mixed, marks=marks)\n",
    "    # shuffle\n",
    "    perm = permutation(len(labels_train_full))\n",
    "    dms_train_full = array(dms_train_full)[perm]\n",
    "    labels_train_full = array(labels_train_full)[perm]\n",
    "    dms_train_full_list.append(dms_train_full)\n",
    "    labels_train_full_list.append(labels_train_full)\n",
    "\n",
    "    file_name = path + pref + \"-r=%d\"%r\n",
    "    np.save(file_name + \"-dms_train\", dms_train_full)\n",
    "    np.save(file_name + \"-labels_train\", labels_train_full)\n",
    "\n",
    "    x0 = array(concatenate([normal(pi, 1, 2*n_tot + (3*n_tot - 1)*n_layers), normal(0, 1, 2**n_meas)]))\n",
    "\n",
    "    fvals_list_r = []\n",
    "    xf_list_r = []\n",
    "    nfev_list_r = []\n",
    "    time_list_r = []\n",
    "    error_test_list_r = []\n",
    "    for n_train in n_train_list:\n",
    "        print(\"\\tT: %d\" %n_train)\n",
    "        \n",
    "        dms_train = dms_train_full[:n_train]\n",
    "        labels_train = labels_train_full[:n_train]\n",
    "\n",
    "        file_name = path + pref + \"-r=%d-Tr=%d\"%(r, n_train)\n",
    "        \n",
    "        print(\"\\t\\tTraining\")\n",
    "        time_start = time()\n",
    "        fvals, result = train(dms_train, labels_train, n_layers, \n",
    "                                  n_copies=n_copies, n_meas=n_meas, x0=x0,\n",
    "                                  method=method, w_ls=w_ls, w_var=w_var, options=options,\n",
    "                                  save_data=True, file_name=file_name, fvals=[])\n",
    "        time_finish = time() - time_start\n",
    "        print(\"\\n\\t\\t\\tFinished in\", time_finish)\n",
    "        print(\"\\t\\t\\t\", result.message)\n",
    "        print(\"\\t\\t\\tCost:\", result.fun)\n",
    "        \n",
    "        print(\"\\t\\tTesting\")\n",
    "    \n",
    "        expecs_test, disps_test = aux_info(dms_test, labels_test, n_layers, result.x, n_copies=n_copies, n_meas=n_meas)\n",
    "        error_test = np.sum((expecs_test - labels_test)**2)\n",
    "        print(\"\\t\\t\\tTesting error:\", error_test)\n",
    "\n",
    "        fvals_list_r.append(fvals)\n",
    "        xf_list_r.append(result.x)\n",
    "        nfev_list_r.append(result.nfev)\n",
    "        time_list_r.append(time_finish)\n",
    "        error_test_list_r.append(error_test)\n",
    "\n",
    "        np.save(file_name + \"-fvals\", array(fvals_list_r, dtype=object))\n",
    "        np.save(file_name + \"-pars\", array(xf_list_r))\n",
    "        np.save(file_name + \"-nfev\", array(nfev_list_r))\n",
    "        np.save(file_name + \"-time\", array(time_list_r))\n",
    "        np.save(file_name + \"-error\", array(error_test_list_r))\n",
    "\n",
    "        x0 = result.x\n",
    "\n",
    "    fvals_list.append(fvals_list_r)\n",
    "    xf_list.append(xf_list_r)\n",
    "    nfev_list.append(nfev_list_r)\n",
    "    time_list.append(time_list_r)\n",
    "    error_test_list.append(error_test_list_r)\n",
    "\n",
    "    file_name = path + pref + \"-r=%d\"%r\n",
    "    np.save(file_name + \"-fvals\", array(fvals_list_r, dtype=object))\n",
    "    np.save(file_name + \"-pars\", array(xf_list_r))\n",
    "    np.save(file_name + \"-nfev\", array(nfev_list_r))\n",
    "    np.save(file_name + \"-time\", array(time_list_r))\n",
    "    np.save(file_name + \"-error\", array(error_test_list_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b610555e-c862-42ef-b3f0-4729642fd41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# method = \"lm\"\n",
    "# method = \"trf\"\n",
    "method = \"dogbox\"\n",
    "\n",
    "# def fit_func(x, a, b): return a*x**(-1/2) + b\n",
    "# def fit_func(x, a, b): return (x**a)*b\n",
    "def fit_func(x, a, b, c): return (x**b)*a + c\n",
    "\n",
    "# popt, pcov = curve_fit(fit_func, n_train_list, np.mean(error_test_list, axis=0), method=method)#, bounds=bounds)\n",
    "popt, pcov = curve_fit(fit_func, n_train_list, np.min(error_test_list, axis=0), method=method)#, bounds=bounds)\n",
    "\n",
    "print(popt)\n",
    "# plt.scatter(n_train_list, np.mean(error_test_list, axis=0))\n",
    "plt.scatter(n_train_list, np.min(error_test_list, axis=0), marker=\"x\")\n",
    "plt.plot(n_train_list, fit_func(n_train_list, *popt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc1818-147a-4eba-8dce-08cc6a85e8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(n_train_list, np.mean(error_test_list, axis=0), yerr=np.std(error_test_list, axis=0), linestyle=\"\", marker=\"o\", markersize=10, capsize=5, label=\"average\")\n",
    "plt.scatter(n_train_list, np.min(error_test_list, axis=0), marker=\"x\", s=100, label=\"minimal\")\n",
    "# plt.plot(n_train_list, [1e6*n_train**(-4/3) for n_train in n_train_list], label=\"fit\")\n",
    "# plt.plot(n_train_list, fit_func(n_train_list, *popt), label=r\"$%.3f\\, T^{%.3f} + %.3f$\" %tuple(popt))\n",
    "plt.xticks(n_train_list[::2], n_train_list[::2])\n",
    "plt.xlabel(r\"$T$, training set size\")\n",
    "plt.ylabel(r\"Testing error\")\n",
    "plt.yscale(\"log\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.errorbar(n_train_list, np.mean(time_list, axis=0), yerr=np.std(time_list, axis=0), marker=\"o\", markersize=10, capsize=5)\n",
    "plt.xticks(n_train_list[::2], n_train_list[::2])\n",
    "plt.xlabel(r\"$T$, training set size\")\n",
    "plt.ylabel(r\"Training time\")\n",
    "plt.title(r\"Average total time: %d seconds\" %np.sum(np.mean(time_list, axis=0)))\n",
    "# plt.yscale(\"log\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.errorbar(n_train_list, np.mean(nfev_list, axis=0), yerr=np.std(nfev_list, axis=0), marker=\"o\", markersize=10, capsize=5)\n",
    "plt.xticks(n_train_list[::2], n_train_list[::2])\n",
    "plt.xlabel(r\"$T$, training set size\")\n",
    "plt.ylabel(r\"Function evaluations\")\n",
    "plt.title(r\"Total function evaluations: %d\" %np.sum(np.mean(nfev_list, axis=0)))\n",
    "# plt.yscale(\"log\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19284ac4-9547-401d-ae44-ed3bc76e73eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0677298c-68a9-48ed-be49-2f5568e878e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05873522-6974-4dc0-ad81-165b6eebe4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875cb75a-f2ec-43a9-9040-0287f9ac71ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f90992c-aff0-46bd-8944-c77bc9667c5c",
   "metadata": {},
   "source": [
    "# Continue run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94a1e542-98c0-4f81-9638-da79067ed087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kardashin/Work/QPE/Results/Entanglement/Training_set_size/c=4-m=8-l=2-w_ls=1.0-w_var=0.0001-T=(100,1000,100)-BFGS'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inp = 2\n",
    "n_copies = 4\n",
    "n_layers = 2\n",
    "n_tot = n_inp*n_copies\n",
    "n_meas = n_inp*n_copies\n",
    "\n",
    "w_ls = 1e0\n",
    "w_var = 1e-4\n",
    "method = \"BFGS\"\n",
    "options = {\"maxiter\": 1500}#, \"maxfun\": int(1e10)}##\n",
    "T_min, T_max_old, T_step = 100, 1000, 100\n",
    "T_max = 1000\n",
    "n_train_list = arange(T_min, T_max_old + 1, T_step)\n",
    "\n",
    "r = 0\n",
    "\n",
    "\n",
    "path = \"/home/kardashin/Work/QPE/Results/Entanglement/Training_set_size/\"\n",
    "# path = \"C:\\\\Users\\\\karda\\\\Work\\\\QPE\\\\Results\\\\Entanglement\\\\Training_set_size\\\\\"\n",
    "pref = \"c=%d-m=%d-l=%d-w_ls=%.1f-w_var=%.4f-T=(%d,%d,%d)-%s\" %(n_copies, n_meas, n_layers, w_ls, w_var, T_min, T_max_old, T_step, method)\n",
    "path = path + pref + \"/\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c7ea197-b2b7-42b9-9719-15d53ccd5d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\r"
     ]
    }
   ],
   "source": [
    "file_name = path + pref + \"-r=%d\"%r\n",
    "\n",
    "dms_train_full = np.load(file_name + \"-dms_train.npy\", allow_pickle=True)\n",
    "labels_train_full = np.load(file_name + \"-labels_train.npy\", allow_pickle=True)\n",
    "\n",
    "dms_train_add, labels_train_add = gen_even_ent_data(T_max - T_max_old, n_inp=n_inp, mixed=True, marks=\"neg\")\n",
    "perm = permutation(T_max - T_max_old)\n",
    "dms_train_add = array(dms_train_add)[perm]\n",
    "labels_train_add = array(labels_train_add)[perm]\n",
    "\n",
    "dms_train_full = concatenate([dms_train_full, dms_train_add])\n",
    "labels_train_full = concatenate([labels_train_full, labels_train_add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db660433-8166-45fe-8f07-019e974325ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fvals_list_r = list(np.load(file_name + \"-fvals.npy\", allow_pickle=True))\n",
    "xf_list_r = list(np.load(file_name + \"-pars.npy\", allow_pickle=True))\n",
    "nfev_list_r = list(np.load(file_name + \"-nfev.npy\", allow_pickle=True))\n",
    "time_list_r = list(np.load(file_name + \"-time.npy\", allow_pickle=True))\n",
    "error_test_list_r = list(np.load(file_name + \"-error.npy\", allow_pickle=True))\n",
    "\n",
    "x0 = xf_list_r[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9352006-57e0-4e8c-a4d3-98fbded0fd76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kardashin/Work/QPE/Results/Entanglement/Training_set_size/c=4-m=8-l=2-w_ls=1.0-w_var=0.0001-T=(100,1000,100)-BFGS/'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/home/kardashin/Work/QPE/Results/Entanglement/Training_set_size/\"\n",
    "pref = \"c=%d-m=%d-l=%d-w_ls=%.1f-w_var=%.4f-T=(%d,%d,%d)-%s\" %(n_copies, n_meas, n_layers, w_ls, w_var, T_min, T_max, T_step, method)\n",
    "path = path + pref + \"/\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41519a6c-e167-4f2d-9b7f-de496fa147a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path + pref + \"-r=%d\"%r + \"-dms_train\", dms_train_full)\n",
    "np.save(path + pref + \"-r=%d\"%r + \"-labels_train\", labels_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ebcdc2d-5ad6-47b5-9d17-2b10d506afd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tT: 900\n",
      "\t\tTraining\n",
      "\t\t\tIteration: 895 | Cost: 1.39423879 | Time passed: 272794 s\n",
      "\t\t\tFinished in 272794.3372476101\n",
      "\t\t\t Optimization terminated successfully.\n",
      "\t\t\tCost: 1.3942387869332553\n",
      "\t\tTesting\n",
      "\t\t\tTesting error: 25.122806917850244\n",
      "\tT: 1000\n",
      "\t\tTraining\n",
      "\t\t\tIteration: 528 | Cost: 1.60778138 | Time passed: 173741 s\n",
      "\t\t\tFinished in 173741.9537167549\n",
      "\t\t\t Optimization terminated successfully.\n",
      "\t\t\tCost: 1.6077813783072126\n",
      "\t\tTesting\n",
      "\t\t\tTesting error: 23.68100002332551\n"
     ]
    }
   ],
   "source": [
    "for n_train in arange(T_max_old + T_step, T_max + 1, T_step):\n",
    "    print(\"\\tT: %d\" %n_train)\n",
    "\n",
    "    dms_train = dms_train_full[:n_train]\n",
    "    labels_train = labels_train_full[:n_train]\n",
    "\n",
    "    file_name = path + pref + \"-r=%d-Tr=%d\"%(r, n_train)\n",
    "\n",
    "    print(\"\\t\\tTraining\")\n",
    "    time_start = time()\n",
    "    fvals, result = train(dms_train, labels_train, n_layers, \n",
    "                              n_copies=n_copies, n_meas=n_meas, x0=x0,\n",
    "                              method=method, w_ls=w_ls, w_var=w_var, options=options,\n",
    "                              save_data=True, file_name=file_name)\n",
    "    time_finish = time() - time_start\n",
    "    print(\"\\n\\t\\t\\tFinished in\", time_finish)\n",
    "    print(\"\\t\\t\\t\", result.message)\n",
    "    print(\"\\t\\t\\tCost:\", result.fun)\n",
    "\n",
    "    x0 = result.x\n",
    "\n",
    "    print(\"\\t\\tTesting\")\n",
    "\n",
    "    expecs_test, disps_test = aux_info(dms_test, labels_test, n_layers, result.x, n_copies=n_copies, n_meas=n_meas)\n",
    "    error_test = np.sum((expecs_test - labels_test)**2)\n",
    "    print(\"\\t\\t\\tTesting error:\", error_test)\n",
    "\n",
    "    fvals_list_r.append(fvals)\n",
    "    xf_list_r.append(result.x)\n",
    "    nfev_list_r.append(result.nfev)\n",
    "    time_list_r.append(time_finish)\n",
    "    error_test_list_r.append(error_test)\n",
    "\n",
    "    np.save(file_name + \"-fvals\", array(fvals_list_r, dtype=object))\n",
    "    np.save(file_name + \"-pars\", array(xf_list_r))\n",
    "    np.save(file_name + \"-nfev\", array(nfev_list_r))\n",
    "    np.save(file_name + \"-time\", array(time_list_r))\n",
    "    np.save(file_name + \"-error\", array(error_test_list_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c12505f-c513-4702-9109-92b794a71ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = path + pref + \"-r=%d\"%r\n",
    "np.save(file_name + \"-fvals\", array(fvals_list_r, dtype=object))\n",
    "np.save(file_name + \"-pars\", array(xf_list_r))\n",
    "np.save(file_name + \"-nfev\", array(nfev_list_r))\n",
    "np.save(file_name + \"-time\", array(time_list_r))\n",
    "np.save(file_name + \"-error\", array(error_test_list_r))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
